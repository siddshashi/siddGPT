//this will include:
//  layernorm
//  single attention head
//  multiple-head attention
//  feedforward MLP
//  dropout
//  connecting everything with blocks, residual connections
//  evaluating loss, cross-entropy
//  backprop with optimizer


// pub struct Transformer {
    // lm head
    // blocks
    // final layer norm
    // embedding table of token + position
// }

// impl Transformer {
    // crate
    // pub fn new() -> Result<Transformer, Box<dyn Error>> {
        // println!("creating transformer...");

    // }
    
    // train
    
    // generate
// }
pub mod linear;
